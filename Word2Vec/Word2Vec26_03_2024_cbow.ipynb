{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b21851e",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6db03b82-98d8-40dd-ae5f-96b4f256536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_FOLDER = 'model/'\n",
    "\n",
    "seed = 88\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6de5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "\n",
    "# Read the CSV file with specified column names\n",
    "df = pd.read_csv(\"../dataset/training.1600000.processed.noemoticon.csv\", \n",
    "                 encoding=\"ISO-8859-1\", names=column_names)\n",
    "\n",
    "def reduce_sample(df, frac, random_state):\n",
    "    df = df.sample(frac=frac, random_state=random_state)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "frac_pop = 1\n",
    "df = reduce_sample(df, frac_pop, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6aa034",
   "metadata": {},
   "source": [
    "Columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "477335fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the original dataset:\n",
      "\n",
      "Index(['target', 'id', 'date', 'flag', 'user', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the original dataset:\\n\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2a23b",
   "metadata": {},
   "source": [
    "Example of an Row in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "689c8807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974058893</td>\n",
       "      <td>Sat May 30 12:21:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BrookeAmanda</td>\n",
       "      <td>Ok it's only been a couple hours since dad has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1998068077</td>\n",
       "      <td>Mon Jun 01 17:56:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KarinaKornacka</td>\n",
       "      <td>@graceofrhythm HAHA no i would never do that!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1999729993</td>\n",
       "      <td>Mon Jun 01 20:43:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>stevegaghagen</td>\n",
       "      <td>Law of Attraction Creations: Law of Attraction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2006627206</td>\n",
       "      <td>Tue Jun 02 11:26:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Hecie</td>\n",
       "      <td>is ordering ticketsssss  EEEE (: &amp;lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1991292674</td>\n",
       "      <td>Mon Jun 01 06:46:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>shanaloren</td>\n",
       "      <td>@STO_MAC nah im not mad at u....luv u too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag            user  \\\n",
       "0       0  1974058893  Sat May 30 12:21:30 PDT 2009  NO_QUERY    BrookeAmanda   \n",
       "1       4  1998068077  Mon Jun 01 17:56:23 PDT 2009  NO_QUERY  KarinaKornacka   \n",
       "2       4  1999729993  Mon Jun 01 20:43:12 PDT 2009  NO_QUERY   stevegaghagen   \n",
       "3       4  2006627206  Tue Jun 02 11:26:46 PDT 2009  NO_QUERY           Hecie   \n",
       "4       4  1991292674  Mon Jun 01 06:46:16 PDT 2009  NO_QUERY      shanaloren   \n",
       "\n",
       "                                                text  \n",
       "0  Ok it's only been a couple hours since dad has...  \n",
       "1  @graceofrhythm HAHA no i would never do that!!...  \n",
       "2  Law of Attraction Creations: Law of Attraction...  \n",
       "3             is ordering ticketsssss  EEEE (: &lt;3  \n",
       "4         @STO_MAC nah im not mad at u....luv u too   "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d146b21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.998818e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000001e+00</td>\n",
       "      <td>1.935761e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.467810e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.956916e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.002102e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.177059e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.329206e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target            id\n",
       "count  1.600000e+06  1.600000e+06\n",
       "mean   2.000000e+00  1.998818e+09\n",
       "std    2.000001e+00  1.935761e+08\n",
       "min    0.000000e+00  1.467810e+09\n",
       "25%    0.000000e+00  1.956916e+09\n",
       "50%    2.000000e+00  2.002102e+09\n",
       "75%    4.000000e+00  2.177059e+09\n",
       "max    4.000000e+00  2.329206e+09"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9c1c4",
   "metadata": {},
   "source": [
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "32c21871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df, drop_columns):\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned = df_cleaned.drop_duplicates()\n",
    "    df_cleaned = df_cleaned.drop(columns=drop_columns)\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    df_cleaned.describe()\n",
    "    return df_cleaned\n",
    "\n",
    "df_cleaned = clean_dataset(df, [\"date\", \"id\", \"flag\", \"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a6f5b54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok it's only been a couple hours since dad has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>@graceofrhythm HAHA no i would never do that!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Law of Attraction Creations: Law of Attraction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>is ordering ticketsssss  EEEE (: &amp;lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@STO_MAC nah im not mad at u....luv u too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Ok it's only been a couple hours since dad has...\n",
       "1       4  @graceofrhythm HAHA no i would never do that!!...\n",
       "2       4  Law of Attraction Creations: Law of Attraction...\n",
       "3       4             is ordering ticketsssss  EEEE (: &lt;3\n",
       "4       4         @STO_MAC nah im not mad at u....luv u too "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b04e21",
   "metadata": {},
   "source": [
    "Remove twitter tag and hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "53ca08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_hashtag(df_cleaned):\n",
    "    df_cleaned['text'] = df_cleaned['text'].apply(lambda x: re.sub(r\"http\\S+|@\\S+|#\\S+\", \"\", x))\n",
    "    return df_cleaned\n",
    "\n",
    "df_cleaned = remove_hashtag(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ba2ef7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok it's only been a couple hours since dad has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>HAHA no i would never do that!!! I actually m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Law of Attraction Creations: Law of Attraction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>is ordering ticketsssss  EEEE (: &amp;lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nah im not mad at u....luv u too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Ok it's only been a couple hours since dad has...\n",
       "1       4   HAHA no i would never do that!!! I actually m...\n",
       "2       4  Law of Attraction Creations: Law of Attraction...\n",
       "3       4             is ordering ticketsssss  EEEE (: &lt;3\n",
       "4       4                  nah im not mad at u....luv u too "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268dec6",
   "metadata": {},
   "source": [
    "convert target back to -1 0 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e9ee2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "-1    800000\n",
       " 1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_unitary_target(df_cleaned, target_column):\n",
    "    df_cleaned[target_column] = df_cleaned[target_column].map({0: -1, 2: 0, 4: 1})\n",
    "    return df_cleaned\n",
    "\n",
    "df_cleaned = convert_to_unitary_target(df_cleaned, 'target')\n",
    "df_cleaned['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d13f1",
   "metadata": {},
   "source": [
    "Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "eb2af120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ok, it, only, been, couple, hours, since, dad...\n",
       "1    [haha, no, would, never, do, that, actually, m...\n",
       "2    [law, of, attraction, creations, law, of, attr...\n",
       "3                [is, ordering, ticketsssss, eeee, lt]\n",
       "4                    [nah, im, not, mad, at, luv, too]\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(df_cleaned, text_column, tokenized_text_column):\n",
    "    from gensim.utils import simple_preprocess\n",
    "    # Tokenize the text column to get the new column 'tokenized_text'\n",
    "    df_cleaned[tokenized_text_column] = [simple_preprocess(line, deacc=True) for line in df_cleaned[text_column]]\n",
    "    return df_cleaned\n",
    "    \n",
    "df_cleaned = tokenize_text(df_cleaned, 'text', 'tokenized_text')\n",
    "df_cleaned['tokenized_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c96433",
   "metadata": {},
   "source": [
    "# Stemming & Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6c904fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_stemmed = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d4957",
   "metadata": {},
   "source": [
    "### PoterStammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ad6379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from gensim.parsing.porter import PorterStemmer\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    df_potter_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_potter_stemmed[stemmed_text_column] = [[porter_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_potter_stemmed[token_text_column]]  \n",
    "    return df_potter_stemmed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fc115",
   "metadata": {},
   "source": [
    "### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e0011d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lancaster_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.lancaster import LancasterStemmer\n",
    "    lancaster_stemmer = LancasterStemmer()\n",
    "    df_lancaster_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_lancaster_stemmed[stemmed_text_column] = [[lancaster_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_lancaster_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_lancaster_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424002e9",
   "metadata": {},
   "source": [
    "### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4020d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowball_stemmer_on_text(df_to_be_stemmed, token_text_column, stemmed_text_column):\n",
    "    from nltk.stem.snowball import EnglishStemmer\n",
    "    snowball_stemmer = EnglishStemmer()\n",
    "    df_snowball_stemmed = df_to_be_stemmed.copy()\n",
    "    # Get the stemmed_tokens\n",
    "    df_snowball_stemmed[stemmed_text_column] = [[snowball_stemmer.stem(word) for word in tokens] \n",
    "                                        for tokens in df_snowball_stemmed[token_text_column]]\n",
    "    \n",
    "    return df_snowball_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453e96e",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a0c4ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(df_to_be_stemmed, token_text_column, lemmatized_text_column):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    df_lemmatized = df_to_be_stemmed.copy()\n",
    "    \n",
    "    # Get the lemmatized_tokens\n",
    "    df_lemmatized[lemmatized_text_column] = [[wordnet_lemmatizer.lemmatize(word) for word in tokens] \n",
    "                                          for tokens in df_lemmatized[token_text_column]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f40c074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ok, it, onli, been, coupl, hour, sinc, dad, h...\n",
       "1    [haha, no, would, never, do, that, actual, mad...\n",
       "2    [law, of, attract, creation, law, of, attract,...\n",
       "3                   [is, order, ticketsssss, eeee, lt]\n",
       "4                    [nah, im, not, mad, at, luv, too]\n",
       "5    [centuri, room, tast, the, rainbow, with, your...\n",
       "6    [ari, also, got, servic, award, for, the, comm...\n",
       "7    [man, thought, somethin, wa, fina, go, done, s...\n",
       "8           [leav, moscow, when, it, final, get, warm]\n",
       "9                           [wish, got, summer, break]\n",
       "Name: stemmed_text, dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_potter_stemmed = porter_stemmer_on_text(df_to_be_stemmed, 'tokenized_text', 'stemmed_text')\n",
    "df_potter_stemmed['stemmed_text'].head(10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e0074",
   "metadata": {},
   "source": [
    "## Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bda16",
   "metadata": {},
   "source": [
    "- Train data ( Subset of data for training ML Model) ~70%\n",
    "- Test data (Subset of data for testing ML Model trained from the train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a2e99184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "target\n",
      " 1    560206\n",
      "-1    559794\n",
      "Name: count, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "target\n",
      "-1    240206\n",
      " 1    239794\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "     index                                       stemmed_text\n",
      "0  1448643  [hiya, davina, think, you, re, great, soooo, l...\n",
      "1  1423081  [tadi, se, neda, pracovat, sous, nade, mnou, d...\n",
      "2  1598349  [photo, eatsleepdraw, iti, ½ll, be, sick, for,...\n",
      "3   405940  [to, top, that, off, my, tricep, ar, kill, me,...\n",
      "4  1050615  [saw, box, full, of, star, war, miniatur, toda...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(data, sentiment_value_col, tokenised_text_col, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( data[tokenised_text_col],\n",
    "                                                        data[sentiment_value_col], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(df_potter_stemmed, 'target', 'stemmed_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c2ac1",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339bfb7",
   "metadata": {},
   "source": [
    "## Save-gram approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87617e6",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76083db",
   "metadata": {},
   "source": [
    "vector_size (int, optional) – Dimensionality of the word vectors.\n",
    "\n",
    "window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "\n",
    "workers (int, optional) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16df688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word2vec_model(stemmed_df, file_name_code, stem_column_name, sg, vector_size, window, min_count, workers):\n",
    "    from gensim.models import Word2Vec\n",
    "    # Skip-gram model (sg = 1)\n",
    "    filename = f\"{file_name_code}_wind_{window}_min_{min_count}_workers_{workers}.wordvectors\"\n",
    "    stemmed_tokens = pd.Series(stemmed_df[stem_column_name]).values\n",
    "    # Train the Word2Vec Model\n",
    "    w2v_model = Word2Vec(stemmed_tokens, min_count = min_count, vector_size = vector_size, workers = workers, window = window, sg = sg, cbow_mean = 1)\n",
    "    w2v_model_wv = w2v_model.wv\n",
    "    w2v_model_wv.save(OUTPUT_FOLDER + filename)\n",
    "\n",
    "    return w2v_model_wv, OUTPUT_FOLDER + filename\n",
    "\n",
    "vector_size = 100\n",
    "sg = 0\n",
    "file_name_code = f\"vec_sz_{vector_size}_sg_{sg}_frac_pop_{frac_pop}\"\n",
    "OUTPUT_FOLDER = 'model/' + file_name_code + '/'\n",
    "import os\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "\n",
    "w2v_model_wv, output_name = generate_word2vec_model(df_potter_stemmed, file_name_code,'stemmed_text', sg = sg, vector_size=vector_size, min_count=1, window=8, workers=100)\n",
    "\n",
    "# print(w2v_model_cbow_wv.most_similar('good'))\n",
    "# print(w2v_model_sg_wv.most_similar('good'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d34b8",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7d749099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "# Load the model from the model file\n",
    "\n",
    "def load_word2vec_model(reduced_mode_file, stem_column_name):\n",
    "    sg_w2v_model_wv = KeyedVectors.load(reduced_mode_file)\n",
    "    # # Unique ID of the word\n",
    "    # print(\"Index of the word 'action':\")\n",
    "    # print(sg_w2v_model_wv.key_to_index[\"action\"])\n",
    "    # # Total number of the words\n",
    "    # print(len(sg_w2v_model_wv.key_to_index))\n",
    "    # # Print the size of the word2vec vector for one word\n",
    "    # print(\"Length of the vector generated for a word\")\n",
    "    # print(len(sg_w2v_model_wv['action']))\n",
    "    # # Get the mean for the vectors for an example review\n",
    "    # print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "    # print(np.mean([sg_w2v_model_wv[token] for token in df_potter_stemmed[stem_column_name][0]], axis=0))\n",
    "    return sg_w2v_model_wv\n",
    "    \n",
    "w2v_model_wv = load_word2vec_model(output_name, 'stemmed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9be7ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\Machine Learning\\NamMLJourney\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Nam\\Documents\\Machine Learning\\NamMLJourney\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def save_word2vec_to_csv(X_set, sg_w2v_model_wv, stem_col, word2vec_filename):\n",
    "    with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "        for index, row in X_set.iterrows():\n",
    "            v_norm = (np.mean([sg_w2v_model_wv[token] for token in row[stem_col]], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(vector_size))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            # Check if the line exists else it is vector of zeros\n",
    "            if type(v_norm) is list:  \n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in v_norm] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(vector_size)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "           \n",
    "\n",
    "    \n",
    "train_X_word2vec_filename = OUTPUT_FOLDER +  f\"train_X_{file_name_code}.csv\"\n",
    "test_X_word2vec_filename = OUTPUT_FOLDER + f\"test_X_{file_name_code}.csv\"\n",
    "\n",
    "\n",
    "save_word2vec_to_csv(X_train, w2v_model_wv, \"stemmed_text\", train_X_word2vec_filename)\n",
    "save_word2vec_to_csv(X_test, w2v_model_wv, \"stemmed_text\", test_X_word2vec_filename)\n",
    "\n",
    "# save_word2vec_to_csv(X_train, w2v_model_cbow_wv, \"stemmed_text\", train_X_word2vec_cbow_filename)\n",
    "# save_word2vec_to_csv(X_test, w2v_model_cbow_wv, \"stemmed_text\", test_X_word2vec_cbow_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d30c3b",
   "metadata": {},
   "source": [
    "## Load Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "11a6e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_w2v_from_csv(word2vec_filename):\n",
    "    train_word2vec_df = pd.read_csv(word2vec_filename)\n",
    "    return train_word2vec_df\n",
    "\n",
    "def load_test_wv_w2v_from_csv(test_X_word2vec_filename):\n",
    "    return pd.read_csv(test_X_word2vec_filename)\n",
    "\n",
    "def generate_X_w2v_df(X_set, w2v_model_wv, stem_column_name):\n",
    "    X_wv = []\n",
    "    for index, row in X_set.iterrows():\n",
    "        model_vector = (np.mean([w2v_model_wv[token] for token in row[stem_column_name]], axis=0))\n",
    "        if model_vector.shape == () :\n",
    "            model_vector = np.zeros(vector_size)\n",
    "        X_wv.append(model_vector.reshape(1, -1))\n",
    "    return pd.DataFrame(np.concatenate(X_wv, axis=0))\n",
    "\n",
    "X_train_wv = load_train_w2v_from_csv(train_X_word2vec_filename)\n",
    "X_test_wv = load_test_wv_w2v_from_csv(test_X_word2vec_filename)\n",
    "\n",
    "# X_train_wv = generate_X_w2v_df(X_train, w2v_model_wv, \"stemmed_text\")\n",
    "# X_test_wv = generate_X_w2v_df(X_test, w2v_model_wv, \"stemmed_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2ebea",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a4a64",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fc03c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree_word2vec(X_train_wv, Y_train, file_name_code):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = DecisionTreeClassifier()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train['target'])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'clf_dt_cbow_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "clf_decision_word2vec = train_decision_tree_word2vec(X_train_wv, Y_train, file_name_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25b987",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bb353250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.65      0.65    240206\n",
      "           1       0.65      0.65      0.65    239794\n",
      "\n",
      "    accuracy                           0.65    480000\n",
      "   macro avg       0.65      0.65      0.65    480000\n",
      "weighted avg       0.65      0.65      0.65    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_decision_tree_word2vec(Y_test, X_test_wv, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test['target'], test_predictions_word2vec))\n",
    "\n",
    "test_decision_tree_word2vec(Y_test, X_test_wv, clf_decision_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0097b",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dbe03",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fe2254ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nam\\Documents\\Machine Learning\\NamMLJourney\\.venv\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_linear_svc(X_train_wv, Y_train, file_name_code):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = LinearSVC()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train['target'])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'l_svc_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "svc_clf = train_linear_svc(X_train_wv, Y_train, file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6e4257f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.76      0.76    240206\n",
      "           1       0.76      0.76      0.76    239794\n",
      "\n",
      "    accuracy                           0.76    480000\n",
      "   macro avg       0.76      0.76      0.76    480000\n",
      "weighted avg       0.76      0.76      0.76    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_linear_svc(Y_test, X_test_wv, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test['target'], test_predictions_word2vec))\n",
    "\n",
    "test_linear_svc(Y_test, X_test_wv, svc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd2d42",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ba1cda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_clf(X_train_wv, Y_train, file_name_code):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = RandomForestClassifier()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train['target'])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'random_forest_dt_clf_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "clf_rfdt = train_random_forest_clf(X_train_wv, Y_train, file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "af327203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.77      0.76    240206\n",
      "           1       0.77      0.75      0.76    239794\n",
      "\n",
      "    accuracy                           0.76    480000\n",
      "   macro avg       0.76      0.76      0.76    480000\n",
      "weighted avg       0.76      0.76      0.76    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_random_forest_clf(Y_test, X_test_wv, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    # from joblib import load\n",
    "    # clf = load(OUTPUT_FOLDER + 'svm_classifier_scl_linear.pkl')\n",
    "    test_predictions_word2vec_svm_scaled = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test['target'], test_predictions_word2vec_svm_scaled))\n",
    "\n",
    "test_random_forest_clf(Y_test, X_test_wv, clf_rfdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776076fb",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a810f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bay(X_train_wv, Y_train, file_name_code):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #Initialize the model\n",
    "    clf_decision_word2vec = GaussianNB()\n",
    "    # Fit the model\n",
    "    clf_decision_word2vec.fit(X_train_wv, Y_train['target'])\n",
    "\n",
    "    import joblib\n",
    "    joblib.dump(clf_decision_word2vec, OUTPUT_FOLDER + f'gauss_NB_{file_name_code}.pkl')\n",
    "\n",
    "    return clf_decision_word2vec\n",
    "\n",
    "svc_clf = train_naive_bay(X_train_wv, Y_train, file_name_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "18f7a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.81      0.70    240206\n",
      "           1       0.73      0.50      0.60    239794\n",
      "\n",
      "    accuracy                           0.66    480000\n",
      "   macro avg       0.68      0.66      0.65    480000\n",
      "weighted avg       0.68      0.66      0.65    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_naive_bay(Y_test, X_test_wv, clf):\n",
    "    from sklearn.metrics import classification_report\n",
    "    test_predictions_word2vec = clf.predict(X_test_wv)\n",
    "\n",
    "    print(classification_report(Y_test['target'], test_predictions_word2vec))\n",
    "\n",
    "test_naive_bay(Y_test, X_test_wv, svc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24263449",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce202bc",
   "metadata": {},
   "source": [
    "\n",
    "## Trial 1 26/3/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d5879",
   "metadata": {},
   "source": [
    "- vector size = 100\n",
    "- sg = 1\n",
    "- frac_pop = 1\n",
    "\n",
    "W2V size = 90KB\n",
    "\n",
    "|Model name | Setting | F1 | Accuracy | Size|\n",
    "|-----------|----------|----|----------|------|\n",
    "|Decision tree | DEFAULT | 0.66 | 0.66| 19,000 KB|\n",
    "|Linear SVC | DEFAULT | 0.76 | 0.76 | 3KB |\n",
    "|Random Forest | DEFAULT | 0.76 | 0.76 | 1.9e6 KB|\n",
    "|Gauss NB| DEFAULT | 0.70\\0.60 | 0.66 | 6KB |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591d5ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327da73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776796b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
